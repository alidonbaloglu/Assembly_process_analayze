import cv2
import numpy as np
from ultralytics import YOLO
import json
import time
from typing import Dict, List, Optional, Tuple, Any

class TaskStartPointDetector:
    """
    Task Start Point Detection (TSPD) AlgoritmasÄ±
    
    Video akÄ±ÅŸÄ±nda nesne deÄŸiÅŸimlerini ve hareket modellerini analiz ederek
    gerÃ§ek gÃ¶rev geÃ§iÅŸlerini tespit eder.
    """
    
    def __init__(self, yolo_model_path: str, confidence_threshold: float = 0.7, task_definition_mode: str = "manual"):
        """
        TSPD sÄ±nÄ±fÄ±nÄ± baÅŸlatÄ±r
        
        Args:
            yolo_model_path: YOLO model dosyasÄ±nÄ±n yolu
            confidence_threshold: YOLO tahmin gÃ¼ven eÅŸiÄŸi
            task_definition_mode: GÃ¶rev tanÄ±mlama modu ("manual", "semantic", "contextual")
        """
        self.yolo_model = YOLO(yolo_model_path)
        self.confidence_threshold = confidence_threshold
        self.task_definition_mode = task_definition_mode
        
        # Algoritma deÄŸiÅŸkenleri
        self.yolo_previous = None
        self.yolo_current = None
        self.n = 0  # GÃ¶rev sayacÄ±
        self.s = 0  # BaÅŸlangÄ±Ã§ frame numarasÄ±
        
        # Veri saklama
        self.task_history = []
        self.frame_buffer = []
        self.detection_log = []
        
        # GÃ¶rev tanÄ±mlama sistemi
        self.task_definitions = self._initialize_task_definitions()
        self.object_stability_buffer = []  # Nesne kararlÄ±lÄ±ÄŸÄ± iÃ§in
        self.min_stability_frames = 3  # Minimum kararlÄ± frame sayÄ±sÄ±
        
        # SÄ±ralÄ± gÃ¶rev takibi: yalnÄ±zca ilk tespitler Ã¶nemlidir
        self.task_order = ["fixture", # bazÄ± gÃ¶revelri gruplamak lazÄ±m grup iÃ§inde sÄ±ra deÄŸiÅŸiklikleri kÃ¼Ã§Ã¼k hata olarak algÄ±lansÄ±n ama hepsinin yapÄ±lmasÄ± kontrol edilsin
                           "reflector",
                            "pcb",
                            "button_hand",
                            "screwing",
                            "test_connector",
                            "black_connector",
                            "button_hand",
                            "power_connector",
                            "fixture"]
        self.expected_task_idx = 0  # Beklenen bir sonraki gÃ¶revin indeksini izler
        self.current_task_name = None  # BaÅŸlamÄ±ÅŸ olan mevcut gÃ¶rev
        self.last_detections = []  # Son frame'deki tÃ¼m tespitler (gÃ¶rselleÅŸtirme iÃ§in)
        # SÄ±nÄ±f bazlÄ± renkler (BGR)
        self.class_colors = {
            'reflector': (0, 0, 255),    # KÄ±rmÄ±zÄ±
            'pcb': (0, 255, 0),        # YeÅŸil
            'screwing': (255, 0, 0),   # Mavi
            'fixture': (0, 165, 255),  # Turuncu
            'button_hand': (255, 0, 255), # Magenta
            'black_connector': (0, 128, 0), # Koyu yeÅŸil
            'test_connector': (128, 0, 128), # Mor
            "power_connector" : (0,255,255),
        }
        # SÄ±ra ihlali uyarÄ±larÄ±
        self.order_violations = []
        self.order_violation_frames_remaining = 0
        self.order_violation_message = None
        # UyarÄ± debounce ve kararlÄ±lÄ±k takibi
        self.violation_cooldown_frames = 0
        self.stable_mismatch_label = None
        self.stable_mismatch_count = 0
        self.min_mismatch_stability_frames = 3 
        
        # GÃ¶rev bitiÅŸi ve bekleme takibi
        self.waiting = False
        self.wait_start_frame = None
        self.last_task_index = None
        self.wait_periods = []
        self.wait_min_seconds = 2.0  # Bekleme kabul eÅŸiÄŸi (saniye)
        self.last_active_task_name = None  # Alt eÅŸik beklemede ekranda gÃ¶stermek iÃ§in
        
    def _initialize_task_definitions(self) -> Dict[str, Any]:
        """
        GÃ¶rev tanÄ±mlama yapÄ±larÄ±nÄ± baÅŸlatÄ±r
        """
        # Åimdilik basit bir baÅŸlangÄ±Ã§ yapÄ±sÄ± dÃ¶ndÃ¼rÃ¼yoruz.
        # Ä°leride "manual", "semantic" veya "contextual" modlarÄ±na gÃ¶re
        # daha geliÅŸmiÅŸ tanÄ±mlar eklenebilir.
        return {}
        
    def yolo_detect(self, frame, expected_object_name: Optional[str] = None) -> Optional[str]:
        """
        YOLO ile nesne tespiti yapar.
        MÃ¼mkÃ¼nse beklenen nesneyi, yoksa en yÃ¼ksek confidence'a sahip nesneyi dÃ¶ndÃ¼rÃ¼r.
        """
        results = self.yolo_model(frame, verbose=False)

        if len(results) == 0 or len(results[0].boxes) == 0:
            self.last_detections = []
            return None, None

        all_boxes = results[0].boxes
        confidences_all = all_boxes.conf.cpu().numpy()
        classes_all = all_boxes.cls.cpu().numpy().astype(int)
        boxes_all = all_boxes.xyxy.cpu().numpy()

        all_detections = []
        best_expected_detection = None
        best_overall_detection = None
        max_overall_conf = 0.0

        for idx in range(len(confidences_all)):
            conf_val = float(confidences_all[idx])
            if conf_val < self.confidence_threshold:
                continue

            class_id_val = int(classes_all[idx])
            class_name_val = self.yolo_model.names[class_id_val]
            bbox_val = boxes_all[idx].tolist()

            current_detection_info = {
                'class': class_name_val,
                'confidence': conf_val,
                'bbox': bbox_val
            }
            all_detections.append(current_detection_info)

            # 1. Beklenen nesneyi ara
            if expected_object_name and class_name_val == expected_object_name:
                if best_expected_detection is None or conf_val > best_expected_detection['confidence']:
                    best_expected_detection = current_detection_info

            # 2. Genel olarak en iyi nesneyi de takip et
            if conf_val > max_overall_conf:
                max_overall_conf = conf_val
                best_overall_detection = current_detection_info

        # Son tespitleri Ã§izim iÃ§in sakla
        self.last_detections = all_detections

        # Karar: Beklenen nesne bulunduysa onu dÃ¶ndÃ¼r
        if best_expected_detection:
            return best_expected_detection['class'], best_expected_detection

        # Beklenen nesne bulunamadÄ±ysa, genel olarak en iyiyi dÃ¶ndÃ¼r
        # (Bu, sÄ±ra hatasÄ± tespiti iÃ§in gereklidir)
        if best_overall_detection:
            return best_overall_detection['class'], best_overall_detection

        return None, None
    
    def run_TETE(self, previous_object: str, frame_range: List[np.ndarray], duration: int):
        """
        TETE (Temporal Event Tracking Engine) simÃ¼lasyonu
        
        Args:
            previous_object: Ã–nceki gÃ¶revdeki nesne
            frame_range: GÃ¶rev sÃ¼resince olan frame'ler
            duration: GÃ¶rev sÃ¼resi (frame sayÄ±sÄ±)
        """
        # TETE analizi (burada basit bir implementasyon)
        tete_result = {
            'previous_object': previous_object,
            'duration_frames': duration,
            'frame_count': len(frame_range),
            'analysis_timestamp': time.time()
        }
        
        print(f"ğŸ” TETE Analysis - Object: {previous_object}, Duration: {duration} frames")
        return tete_result
    
    def detect_task_transition(self, frame_i: int, frame_fi: np.ndarray) -> Optional[Dict]:
        """
        Ana TSPD algoritmasÄ± - GÃ¶rev geÃ§iÅŸlerini tespit eder
        (Senaryo 1'i Ã§Ã¶zmek iÃ§in mantÄ±ÄŸÄ± yeniden yapÄ±landÄ±rÄ±lmÄ±ÅŸ versiyon)
        
        Args:
            frame_i: Frame numarasÄ±
            frame_fi: Frame gÃ¶rÃ¼ntÃ¼sÃ¼
            
        Returns:
            GÃ¶rev geÃ§iÅŸ bilgileri veya None
        """
        # Frame'i buffer'a ekle
        self.frame_buffer.append(frame_fi.copy())
        
        # 1. Beklenen nesneyi Ã–NCE belirle
        expected_name = None
        if self.expected_task_idx < len(self.task_order):
            expected_name = self.task_order[self.expected_task_idx]

        # 2. YOLO'yu beklenen nesneye Ã¶ncelik vererek Ã§aÄŸÄ±r
        detected_name, current_detection_info = self.yolo_detect(frame_fi, expected_name)
        self.yolo_current = detected_name
        
        # Detection log'a ekle (her frame iÃ§in)
        log_entry = {
            'frame': frame_i,
            'detection': detected_name,
            'info': current_detection_info,
            'event': 'detection',
            'expected': expected_name,
            'current_task': self.current_task_name
        }
        self.detection_log.append(log_entry)
        
        # 3. YENÄ° MANTIK AKIÅI
        
        # DURUM A: HiÃ§bir nesne tespit edilmedi (veya eÅŸiÄŸin altÄ±nda)
        if detected_name is None:
            log_entry['event'] = 'no_detection'
            # EÄŸer aktif bir gÃ¶rev varsa, onu bitir ve beklemeye geÃ§
            if self.current_task_name is not None and not self.waiting:
                Dn = frame_i - self.s
                previous_object = self.current_task_name
                task_frames = self.frame_buffer[-(frame_i - self.s + 1):]
                tete_result = self.run_TETE(previous_object, task_frames, Dn)
                task_info = {
                    'task_number': self.n if self.n > 0 else 1,
                    'start_frame': self.s,
                    'end_frame': frame_i,
                    'duration': Dn,
                    'previous_object': previous_object,
                    'current_object': None,
                    'tete_analysis': tete_result,
                    'timestamp': time.time(),
                    'status': 'completed_no_next'
                }
                self.task_history.append(task_info)
                self.last_task_index = len(self.task_history) - 1
                # Bekleme baÅŸlasÄ±n
                self.waiting = True
                self.wait_start_frame = frame_i
                self.last_active_task_name = previous_object
                self.current_task_name = None
                self.s = frame_i
                
                log_entry['event'] = 'task_end_object_lost'
                log_entry['details'] = {'ended_object': previous_object}
            return None

        # Buraya geldiysek, bir nesne tespit edildi
        detected_norm = str(detected_name).strip().lower()
        if self.expected_task_idx >= len(self.task_order):
            # TÃ¼m gÃ¶revler zaten baÅŸlatÄ±ldÄ±/tamamlandÄ± sayÄ±lÄ±r
            return None
        
        # DURUM B: Tespit edilen nesne, BEKLENEN nesne (DoÄŸru sÄ±ra)
        if detected_norm == expected_name:
            # Mismatch kararlÄ±lÄ±k takibini sÄ±fÄ±rla (doÄŸru sÄ±raya dÃ¶nÃ¼ldÃ¼)
            self.stable_mismatch_label = None
            self.stable_mismatch_count = 0
            
            if self.current_task_name is None:
                # B.1: Bu, 'bekleme' (waiting) sonrasÄ± YENÄ° BÄ°R GÃ–REVÄ°N BAÅLANGICI
                log_entry['event'] = 'task_start'
                
                if self.waiting and self.last_task_index is not None:
                    wait_frames = frame_i - (self.wait_start_frame or frame_i)
                    try:
                        fps_val = getattr(self, 'video_fps', 30) or 30
                        wait_seconds = float(wait_frames) / float(fps_val) if fps_val > 0 else 0.0
                        wait_min = float(getattr(self, 'wait_min_seconds', 2.0))
                        if wait_seconds >= wait_min:
                            adj_seconds = max(0.0, wait_seconds - wait_min)
                            adj_frames = int(round(adj_seconds * float(fps_val))) if fps_val > 0 else 0
                            self.task_history[self.last_task_index]['waiting_after_frames'] = adj_frames
                            self.task_history[self.last_task_index]['waiting_after_seconds'] = adj_seconds
                            self.task_history[self.last_task_index]['waiting_after_frames_raw'] = int(wait_frames)
                            self.task_history[self.last_task_index]['waiting_after_seconds_raw'] = wait_seconds
                            self.wait_periods.append({
                                'task_index': self.last_task_index,
                                'task_number': self.task_history[self.last_task_index].get('task_number'),
                                'start_frame': int(self.wait_start_frame or frame_i),
                                'end_frame': int(frame_i),
                                'duration_frames_raw': int(wait_frames),
                                'duration_seconds_raw': wait_seconds,
                                'duration_frames': adj_frames,
                                'duration_seconds': adj_seconds
                            })
                        if self.task_history[self.last_task_index].get('current_object') is None:
                            self.task_history[self.last_task_index]['current_object'] = detected_norm
                    except Exception:
                        pass
                    self.waiting = False
                    self.wait_start_frame = None
                
                # GÃ¶rev baÅŸlangÄ±cÄ±nÄ± iÅŸaretle
                self.current_task_name = detected_norm
                self.last_active_task_name = detected_norm
                self.s = frame_i
                if self.n > 0: self.n += 1
                else: self.n = 1
                
                if self.n == 1: print(f"ğŸ“ Ä°lk gÃ¶rev baÅŸladÄ± - Frame {frame_i}: {detected_name}")
                else: print(f"ğŸ“ Yeni gÃ¶rev baÅŸladÄ± - Frame {frame_i}: {detected_name}")
                
                self.expected_task_idx += 1
                return None # Bu bir 'baÅŸlangÄ±Ã§', 'geÃ§iÅŸ' deÄŸil
            
            elif self.current_task_name == detected_norm:
                # B.2: Halen aynÄ± gÃ¶revin iÃ§indeyiz, bir ÅŸey yapma
                log_entry['event'] = 'task_ongoing'
                return None
                
            else:
                # B.3: Bu, 'reflector'dan 'pcb'ye GÃ–REV GEÃ‡Ä°ÅÄ° (SENARYO 1'Ä°N Ã‡Ã–ZÃœMÃœ)
                log_entry['event'] = 'task_transition'
                
                Dn = frame_i - self.s
                previous_object = self.current_task_name
                current_object = detected_norm
                
                self.n += 1
                print(f"ğŸ¯ GÃ–REV DEÄÄ°ÅÄ°MÄ° TESPÄ°T EDÄ°LDÄ°!")
                print(f"   GÃ¶rev #{self.n}")
                print(f"   {previous_object} â†’ {current_object}")
                print(f"   SÃ¼re: {Dn} frame")
                print(f"   Frame aralÄ±ÄŸÄ±: {self.s} - {frame_i}")
                
                task_frames = self.frame_buffer[-(frame_i - self.s + 1):]
                tete_result = self.run_TETE(previous_object, task_frames, Dn)
                
                task_info = {
                    'task_number': self.n,
                    'start_frame': self.s,
                    'end_frame': frame_i,
                    'duration': Dn,
                    'previous_object': previous_object,
                    'current_object': current_object,
                    'tete_analysis': tete_result,
                    'timestamp': time.time(),
                    'status': 'completed_transition' # Yeni status eklendi
                }
                self.task_history.append(task_info)
                self.last_task_index = len(self.task_history) - 1 # OlasÄ± bir 'wait' iÃ§in indeksi ayarla
                
                # GÃ¼ncellemeler
                self.s = frame_i
                self.current_task_name = current_object
                self.last_active_task_name = current_object
                self.expected_task_idx += 1
                
                if len(self.frame_buffer) > 100:
                    self.frame_buffer = self.frame_buffer[-50:]
                
                return task_info

        # DURUM C: Tespit edilen nesne, BEKLENEN nesne DEÄÄ°L (SÄ±ra HatasÄ±)
        else:
            log_entry['event'] = 'order_violation'
            
            # TamamlanmÄ±ÅŸ aÅŸamalara ait tekrar tespitleri sessizce yoksay
            violation_type = "bilinmeyen"
            try:
                detected_idx = self.task_order.index(detected_norm)
                if detected_idx < self.expected_task_idx:
                    # Ã–nceki aÅŸamaya ait tekrar tespiti: uyarÄ± verme, sadece yoksay
                    log_entry['event'] = 'past_task_ignored'
                    return None
                elif detected_idx > self.expected_task_idx:
                    violation_type = "sirayi atlama"
            except ValueError:
                detected_idx = None
                violation_type = "tanimsiz sinif"

            # UyarÄ± tekrarÄ±nÄ± Ã¶nlemek iÃ§in cooldown uygula
            if self.violation_cooldown_frames and self.violation_cooldown_frames > 0:
                return None

            # KararlÄ±lÄ±k kontrolÃ¼
            if self.stable_mismatch_label == detected_norm:
                self.stable_mismatch_count += 1
            else:
                self.stable_mismatch_label = detected_norm
                self.stable_mismatch_count = 1

            if self.stable_mismatch_count < self.min_mismatch_stability_frames:
                return None # HenÃ¼z kararlÄ± deÄŸil

            warn_msg = f"SIRA HATASI! Beklenen: {expected_name}, Tespit: {detected_norm} ({violation_type})"
            print(f"âš ï¸ {warn_msg} - Frame {frame_i}")

            violation_record = {
                'frame': frame_i,
                'expected': expected_name,
                'detected': detected_norm,
                'violation_type': violation_type,
                'timestamp': time.time()
            }
            self.order_violations.append(violation_record)
            log_entry['details'] = violation_record
            
            # GÃ¶rsel uyarÄ±
            self.order_violation_message = warn_msg
            fps_val = getattr(self, 'video_fps', 30) or 30
            self.order_violation_frames_remaining = max(self.order_violation_frames_remaining, int(2 * fps_val))
            self.violation_cooldown_frames = int(2 * fps_val)
            return None
    
    def process_video(self, video_path: str, output_path: str = None, display: bool = True, mask_path: Optional[str] = None) -> List[Dict]:
        """
        Video dosyasÄ±nÄ± iÅŸler ve gÃ¶rev geÃ§iÅŸlerini tespit eder
        
        Args:
            video_path: Video dosyasÄ±nÄ±n yolu
            output_path: Ã‡Ä±kÄ±ÅŸ video dosyasÄ±nÄ±n yolu (opsiyonel)
            display: Video gÃ¶sterimini aÃ§Ä±k/kapalÄ±
            mask_path: Ä°steÄŸe baÄŸlÄ± maske yolu (beyaz alanlar iÅŸlenecek)
            
        Returns:
            Tespit edilen gÃ¶revlerin listesi video_path
        """
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            raise ValueError(f"Video dosyasÄ± aÃ§Ä±lamadÄ±: {video_path}")
        
        # Video bilgileri
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        print(f"ğŸ“¹ Video bilgileri:")
        print(f"   FPS: {fps}")
        print(f"   Toplam frame: {total_frames}")
        print(f"   Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k: {width}x{height}")
        print(f"   SÃ¼re: {total_frames/fps:.2f} saniye")
        print()
        
        # Maske yÃ¼kle (opsiyonel). Beyaz alanlar iÅŸlenecek, siyah alanlar yoksayÄ±lacak.
        mask_binary = None
        try:
            if mask_path is None:
                mask_path = "mask2.png"
            mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
            if mask_img is not None:
                if mask_img.shape[1] != width or mask_img.shape[0] != height:
                    mask_img = cv2.resize(mask_img, (width, height), interpolation=cv2.INTER_NEAREST)
                _, mask_binary = cv2.threshold(mask_img, 127, 255, cv2.THRESH_BINARY)
                print(f"ğŸ—ºï¸ Maske yÃ¼klendi: {mask_path}")
            else:
                print(f"âš ï¸ Maske okunamadÄ±: {mask_path}. Maske olmadan devam ediliyor.")
        except Exception:
            print("âš ï¸ Maske yÃ¼kleme sÄ±rasÄ±nda hata. Maske olmadan devam ediliyor.")
            mask_binary = None
        
        # Ã‡Ä±kÄ±ÅŸ video yazÄ±cÄ±sÄ± (opsiyonel)
        out_writer = None
        # FPS bilgisini sÄ±nÄ±f seviyesinde sakla (JSON iÃ§in saniye hesaplama)
        self.video_fps = fps
        if output_path:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        frame_count = 0
        prev_time = time.time()
        fps_smooth = float(fps) if fps > 0 else 0.0
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # Maske iÃ§ini iÅŸle (tespit iÃ§in)
                frame_for_detection = frame
                if mask_binary is not None:
                    frame_for_detection = cv2.bitwise_and(frame, frame, mask=mask_binary)
                
                # TSPD algoritmasÄ±nÄ± Ã§alÄ±ÅŸtÄ±r
                task_transition = self.detect_task_transition(frame_count, frame_for_detection)
                
                # GÃ¶rselleÅŸtirme
                display_frame = frame.copy()
                if mask_binary is not None:
                    outside = cv2.bitwise_not(mask_binary)
                    dark = np.zeros_like(display_frame)
                    # DÄ±ÅŸ bÃ¶lgeyi karart
                    display_frame = cv2.add(
                        cv2.bitwise_and(display_frame, display_frame, mask=mask_binary),
                        cv2.bitwise_and(dark, dark, mask=outside)
                    )
                
                # AnlÄ±k FPS hesapla (iÅŸleme FPS'i) ve yumuÅŸat
                now_time = time.time()
                dt = now_time - prev_time
                if dt > 0:
                    inst_fps = 1.0 / dt
                    fps_smooth = 0.9 * fps_smooth + 0.1 * inst_fps
                prev_time = now_time
                
                # TÃ¼m tespitleri Ã§iz (bbox + etiket)
                if hasattr(self, 'last_detections') and self.last_detections:
                    for det in self.last_detections:
                        x1, y1, x2, y2 = map(int, det['bbox'])
                        label = f"{det['class']} {det['confidence']:.2f}"
                        color = self.class_colors.get(str(det['class']).lower(), (0, 255, 255))
                        cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 2)
                        cv2.putText(display_frame,
                                    label,
                                    (x1, max(0, y1 - 10)),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                
                # GÃ¶rev numarasÄ± ve adÄ± / bekleme gÃ¶stergesi
                task_text = "Task: 0"
                if self.current_task_name:
                    task_text = f"Task: {self.n} - {self.current_task_name}"
                elif getattr(self, 'waiting', False) and getattr(self, 'last_task_index', None) is not None:
                    wait_frames_raw = frame_count - (self.wait_start_frame or frame_count)
                    fps_val = getattr(self, 'video_fps', 30) or 30
                    wait_seconds_raw = (float(wait_frames_raw) / float(fps_val)) if fps_val > 0 else 0.0
                    # Ekranda yalnÄ±zca eÅŸik ve Ã¼stÃ¼nÃ¼ gÃ¶ster, ilk 2 saniyeyi dÃ¼ÅŸ
                    if wait_seconds_raw >= float(getattr(self, 'wait_min_seconds', 2.0)):
                        adj_seconds = max(0.0, wait_seconds_raw - float(getattr(self, 'wait_min_seconds', 2.0)))
                        adj_frames = int(round(adj_seconds * float(fps_val))) if fps_val > 0 else 0
                        last_task_num = self.task_history[self.last_task_index].get('task_number', '?') if self.task_history else '?'
                        task_text = f"Task: {last_task_num} - delay {adj_frames}f ({adj_seconds:.1f}s)"
                    else:
                        # EÅŸik altÄ± ise mevcut son gÃ¶revi gÃ¶stermeye devam edelim
                        last_task_num = self.task_history[self.last_task_index].get('task_number', '?') if self.task_history else (self.n or 0)
                        last_task_name = self.last_active_task_name or self.current_task_name or ""
                        task_text = f"Task: {last_task_num} - {last_task_name}" if last_task_name else ""
                cv2.putText(display_frame,
                          task_text if task_text else (f"Task: {self.n} - {self.current_task_name}" if self.current_task_name else ""),
                          (10, 70),
                          cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
                
                # FPS bilgisini gÃ¶ster (iÅŸleme FPS'i)
                cv2.putText(display_frame,
                          f"FPS: {fps_smooth:.1f}",
                          (10, 110),
                          cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
                
                # Frame numarasÄ±nÄ± gÃ¶ster
                cv2.putText(display_frame, 
                          f"Frame: {frame_count}", 
                          (10, 150), 
                          cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                
                # GÃ¶rev geÃ§iÅŸi varsa vurgula
                if task_transition:
                    cv2.rectangle(display_frame, (0, 0), (width, height), (0, 255, 255), 5)
                    cv2.putText(display_frame, 
                              "TASK TRANSITION!", 
                              (width//4, height//2), 
                              cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 255), 3)

                # SÄ±ra ihlali gÃ¶rsel uyarÄ±sÄ±
                if self.order_violation_frames_remaining and self.order_violation_frames_remaining > 0:
                    cv2.rectangle(display_frame, (0, 0), (width, height), (0, 0, 255), 6)
                    msg = self.order_violation_message or "SIRA HATASI"
                    cv2.putText(display_frame,
                                msg,
                                (max(10, width//20), max(50, height//10)),
                                cv2.FONT_HERSHEY_SIMPLEX, 1.1, (0, 0, 255), 3)
                    self.order_violation_frames_remaining -= 1
                # Violation cooldown sayacÄ±
                if self.violation_cooldown_frames and self.violation_cooldown_frames > 0:
                    self.violation_cooldown_frames -= 1
                
                # Video gÃ¶sterimi
                if display:
                    cv2.imshow('TSPD - Task Detection', display_frame)
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        print("KullanÄ±cÄ± tarafÄ±ndan durduruldu.")
                        break
                
                # Ã‡Ä±kÄ±ÅŸ videosuna kaydet
                if out_writer:
                    out_writer.write(display_frame)
                
                frame_count += 1
                
                # Progress bar
                if frame_count % (total_frames // 20) == 0:
                    progress = (frame_count / total_frames) * 100
                    print(f"â³ Ä°lerleme: {progress:.1f}%")
                    
        except KeyboardInterrupt:
            print("\nâš ï¸ Ä°ÅŸlem kullanÄ±cÄ± tarafÄ±ndan durduruldu.")
        
        finally:
            cap.release()
            if out_writer:
                out_writer.release()
            if display:
                cv2.destroyAllWindows()
            # Video sonunda aÃ§Ä±k bekleme varsa kapat ve kaydet
            if getattr(self, 'waiting', False) and self.last_task_index is not None:
                end_frame_final = max(0, frame_count - 1)
                wait_frames_final = end_frame_final - (self.wait_start_frame or end_frame_final)
                if wait_frames_final < 0:
                    wait_frames_final = 0
                fps_val = getattr(self, 'video_fps', 30) or 30
                try:
                    wait_seconds_final = float(wait_frames_final) / float(fps_val) if fps_val > 0 else 0.0
                    wait_min = float(getattr(self, 'wait_min_seconds', 2.0))
                    if wait_seconds_final >= wait_min:
                        adj_seconds_f = max(0.0, wait_seconds_final - wait_min)
                        adj_frames_f = int(round(adj_seconds_f * float(fps_val))) if fps_val > 0 else 0
                        self.task_history[self.last_task_index]['waiting_after_frames'] = adj_frames_f
                        self.task_history[self.last_task_index]['waiting_after_seconds'] = adj_seconds_f
                        # Ham deÄŸerleri de ekle
                        self.task_history[self.last_task_index]['waiting_after_frames_raw'] = int(wait_frames_final)
                        self.task_history[self.last_task_index]['waiting_after_seconds_raw'] = wait_seconds_final
                        self.wait_periods.append({
                            'task_index': self.last_task_index,
                            'task_number': self.task_history[self.last_task_index].get('task_number'),
                            'start_frame': int(self.wait_start_frame or end_frame_final),
                            'end_frame': int(end_frame_final),
                            'duration_frames_raw': int(wait_frames_final),
                            'duration_seconds_raw': wait_seconds_final,
                            'duration_frames': adj_frames_f,
                            'duration_seconds': adj_seconds_f,
                            'closed_on_video_end': True
                        })
                except Exception:
                    pass
                self.waiting = False
                self.wait_start_frame = None
        
        return self.task_history
    
    def save_results(self, output_file: str):
        """
        SonuÃ§larÄ± JSON dosyasÄ±na kaydeder
        
        Args:
            output_file: Ã‡Ä±kÄ±ÅŸ dosyasÄ±nÄ±n yolu
        """
        fps_value = getattr(self, 'video_fps', None)
        tasks_with_durations = []
        total_duration_seconds = 0.0
        for t in self.task_history:
            duration_frames = int(t.get('duration', 0))
            duration_seconds = float(duration_frames) / float(fps_value) if fps_value and fps_value > 0 else None
            if duration_seconds is not None:
                total_duration_seconds += duration_seconds
            t_out = dict(t)
            t_out['duration_seconds'] = duration_seconds
            tasks_with_durations.append(t_out)
        
        results = {
            'total_tasks': self.n,
            'total_frames_processed': len(self.detection_log),
            'task_history': tasks_with_durations,
            'detection_log': self.detection_log,
            'order_violations': self.order_violations,
            'wait_periods': self.wait_periods,
            'totals': {
                'total_duration_frames': sum(int(t.get('duration', 0)) for t in self.task_history),
                'total_duration_seconds': total_duration_seconds if fps_value and fps_value > 0 else None,
                'video_fps': fps_value
            },
            'algorithm_settings': {
                'confidence_threshold': self.confidence_threshold
            }
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"ğŸ’¾ SonuÃ§lar kaydedildi: {output_file}")
    
    def print_summary(self):
        """
        Analiz Ã¶zetini yazdÄ±rÄ±r
        """
        print("\n" + "="*50)
        print("ğŸ“Š TSPD ANALÄ°Z Ã–ZETÄ°")
        print("="*50)
        print(f"ğŸ¯ Toplam tespit edilen gÃ¶rev: {self.n}")
        print(f"ğŸ“ Ä°ÅŸlenen toplam frame: {len(self.detection_log)}")
        print()
        
        if self.task_history:
            print("ğŸ“‹ GÃ–REV DETAYLARI:")
            for task in self.task_history:
                print(f"   GÃ¶rev #{task['task_number']}:")
                print(f"      Nesne deÄŸiÅŸimi: {task['previous_object']} â†’ {task['current_object']}")
                print(f"      Frame aralÄ±ÄŸÄ±: {task['start_frame']}-{task['end_frame']}")
                print(f"      SÃ¼re: {task['duration']} frame")
                if 'waiting_after_frames' in task:
                    print(f"      Bekleme: {task['waiting_after_frames']} frame")
                print()
        if getattr(self, 'wait_periods', None):
            print("â±ï¸ BEKLEME PERIYOTLARI:")
            for wp in self.wait_periods:
                print(f"   GÃ¶rev #{wp.get('task_number')}: {wp.get('start_frame')} - {wp.get('end_frame')} ({wp.get('duration_frames')} frame)")
                print()


def main():
    """
    Ana fonksiyon - TSPD algoritmasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±r
    """
    # KullanÄ±m Ã¶rneÄŸi
    print("ğŸš€ TSPD (Task Start Point Detection) AlgoritmasÄ±")
    print("="*60)
    
    # Model ve video yollarÄ± (bu kÄ±sÄ±mlarÄ± kendi dosya yollarÄ±nÄ±zla deÄŸiÅŸtirin)
    YOLO_MODEL_PATH = "Modeller/Makale/Yolov11/M_model/runs/detect/train/weights/best.pt"  # YOLO model dosyasÄ±nÄ±n yolu
    VIDEO_PATH = "C:/Users/ali.donbaloglu/Desktop/Montaj_proces/input_video/eski/part10.mp4"   # Video dosyasÄ±nÄ±n yolu
    OUTPUT_VIDEO_PATH = "output_tspd.mp4"  # Ã‡Ä±kÄ±ÅŸ video dosyasÄ± (opsiyonel)
    RESULTS_JSON_PATH = "tspd_results.json"  # SonuÃ§lar JSON dosyasÄ±
    
    try:
        # TSPD detector'Ä± baÅŸlat
        detector = TaskStartPointDetector(
            yolo_model_path=YOLO_MODEL_PATH,
            confidence_threshold=0.7
        )
        
        print(f"âœ… YOLO model yÃ¼klendi: {YOLO_MODEL_PATH}")
        print(f"ğŸ“¹ Video iÅŸlenecek: {VIDEO_PATH}")
        print()
        
        # Video iÅŸleme
        task_transitions = detector.process_video(
            video_path=VIDEO_PATH,
            output_path=OUTPUT_VIDEO_PATH,
            display=True
        )
        
        # SonuÃ§larÄ± gÃ¶ster
        detector.print_summary()
        
        # SonuÃ§larÄ± kaydet
        detector.save_results(RESULTS_JSON_PATH)
        
        print(f"\nâœ… Ä°ÅŸlem tamamlandÄ±!")
        print(f"ğŸ“Š {len(task_transitions)} gÃ¶rev geÃ§iÅŸi tespit edildi.")
        
    except Exception as e:
        print(f"âŒ Hata: {e}")
        print("LÃ¼tfen model ve video dosya yollarÄ±nÄ± kontrol edin.")


if __name__ == "__main__":
    main()